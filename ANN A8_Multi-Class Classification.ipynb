{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNWuGyzrAxifkn3JEuyrG3o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["A8. Create a Neural network architecture from scratch in Python and use it to do multi-class classification on any data.\n","Parameters to be considered while creating the neural network from scratch are specified as:\n","(1) No of hidden layers : 1 or more\n","(2) No. of neurons in hidden layer: 100\n","(3) Non-linearity in the layer : Relu\n","(4) Use more than 1 neuron in the output layer. Use a suitable threshold value\n","Use appropriate Optimisation algorithm"],"metadata":{"id":"obQA4LlTfD-b"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yVBNkKyOfDZ9","executionInfo":{"status":"ok","timestamp":1746537450300,"user_tz":-330,"elapsed":688,"user":{"displayName":"SRUSHTI DHOTRE","userId":"06050880057213308556"}},"outputId":"56b7c279-cac2-4d90-a6f9-d7410a1fc78b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 2.6277\n","Epoch 100, Loss: 0.0973\n","Epoch 200, Loss: 0.0667\n","Epoch 300, Loss: 0.0532\n","Epoch 400, Loss: 0.0450\n","Epoch 500, Loss: 0.0394\n","Epoch 600, Loss: 0.0349\n","Epoch 700, Loss: 0.0313\n","Epoch 800, Loss: 0.0286\n","Epoch 900, Loss: 0.0262\n","Test Accuracy: 93.33%\n"]}],"source":["import numpy as np\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","\n","# Load and preprocess data\n","iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target.reshape(-1, 1)\n","\n","encoder = OneHotEncoder(sparse_output=False)\n","y = encoder.fit_transform(y)\n","\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize parameters\n","def initialize_parameters(input_size, hidden_size, output_size):\n","    W1 = np.random.randn(input_size, hidden_size)\n","    b1 = np.zeros((1, hidden_size))\n","    W2 = np.random.randn(hidden_size, output_size)\n","    b2 = np.zeros((1, output_size))\n","    return W1, b1, W2, b2\n","\n","# Activation functions\n","def relu(Z):\n","    return np.maximum(0, Z)\n","\n","def relu_derivative(Z):\n","    return (Z > 0).astype(float)\n","\n","def softmax(Z):\n","    exp_Z = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n","    return exp_Z / np.sum(exp_Z, axis=1, keepdims=True)\n","\n","# Forward pass\n","def forward_pass(X, W1, b1, W2, b2):\n","    Z1 = np.dot(X, W1) + b1\n","    A1 = relu(Z1)\n","    Z2 = np.dot(A1, W2) + b2\n","    A2 = softmax(Z2)\n","    return Z1, A1, Z2, A2\n","\n","# Compute loss\n","def compute_loss(y_true, A2):\n","    return -np.mean(y_true * np.log(A2 + 1e-8))\n","\n","# Backward pass\n","def backward_pass(X, y_true, W2, Z1, A1, A2):\n","    m = X.shape[0]\n","    dZ2 = A2 - y_true\n","    dW2 = np.dot(A1.T, dZ2) / m\n","    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n","\n","    dA1 = np.dot(dZ2, W2.T)\n","    dZ1 = dA1 * relu_derivative(Z1)\n","    dW1 = np.dot(X.T, dZ1) / m\n","    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n","\n","    return dW1, db1, dW2, db2\n","\n","# Update parameters\n","def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n","    W1 -= learning_rate * dW1\n","    b1 -= learning_rate * db1\n","    W2 -= learning_rate * dW2\n","    b2 -= learning_rate * db2\n","    return W1, b1, W2, b2\n","\n","# Predict\n","def predict(X, W1, b1, W2, b2):\n","    _, _, _, A2 = forward_pass(X, W1, b1, W2, b2)\n","    return np.argmax(A2, axis=1)\n","\n","# Training loop\n","def train_network(X_train, y_train, input_size, hidden_size, output_size, learning_rate, epochs):\n","    W1, b1, W2, b2 = initialize_parameters(input_size, hidden_size, output_size)\n","\n","    for epoch in range(epochs):\n","        Z1, A1, Z2, A2 = forward_pass(X_train, W1, b1, W2, b2)\n","        loss = compute_loss(y_train, A2)\n","\n","        dW1, db1, dW2, db2 = backward_pass(X_train, y_train, W2, Z1, A1, A2)\n","        W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n","\n","        if epoch % 100 == 0:\n","            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n","\n","    return W1, b1, W2, b2\n","\n","# Train the model\n","input_size = 4\n","hidden_size = 100\n","output_size = 3\n","learning_rate = 0.01\n","epochs = 1000\n","\n","W1, b1, W2, b2 = train_network(X_train, y_train, input_size, hidden_size, output_size, learning_rate, epochs)\n","\n","# Evaluate the model\n","predictions = predict(X_test, W1, b1, W2, b2)\n","y_test_labels = np.argmax(y_test, axis=1)\n","accuracy = np.mean(predictions == y_test_labels)\n","print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"]},{"cell_type":"code","source":[],"metadata":{"id":"ruMYkckuuXMg"},"execution_count":null,"outputs":[]}]}