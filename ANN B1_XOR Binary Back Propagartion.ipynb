{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMjejCEQQzhJPG/NIHKxqjH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["B1. Write a python program to show Back Propagation Network for XOR function with Binary Input and Output."],"metadata":{"id":"mmJOTb51wjzo"}},{"cell_type":"code","source":["import numpy as np\n","\n","def sigmoid(x):\t\t\t\t\t                                                        # Sigmoid activation function and its derivative\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\t\t\t\t\t                        # XOR input and output\n","y = np.array([[0], [1], [1], [0]])\n","\n","np.random.seed(42)\t\t\t\t\t\t\t                                                # Initialize weights and biases\n","\n","W1 = np.random.rand(2, 2)                                                       # Input to hidden weights\n","b1 = np.random.rand(1, 2)                                                       # Hidden layer bias\n","W2 = np.random.rand(2, 1)                                                       # Hidden to output weights\n","b2 = np.random.rand(1, 1)                                                       # Output layer bias\n","\n","lr = 0.1 \t\t\t\t\t\t\t\t\t\t                                                    # Learning rate\n","\n","for epoch in range(10000):\t\t\t\t\t\t                                          # Training the neural network\n","\n","    hidden_input = np.dot(X, W1) + b1\t\t\t\t    \t\t                            # Forward pass\n","    hidden_output = sigmoid(hidden_input)\n","\n","    output_input = np.dot(hidden_output, W2) + b2\n","    output = sigmoid(output_input)\n","\n","    error = y - output\t\t\t\t\t\t\t\t                                          # Compute the error\n","\n","    d_output = error * sigmoid_derivative(output) \t\t\t\t                      # Backpropagation\n","    d_hidden = d_output.dot(W2.T) * sigmoid_derivative(hidden_output)\n","\n","    W2 += hidden_output.T.dot(d_output) * lr \t\t                                # Update weights and biases\n","    b2 += np.sum(d_output, axis=0, keepdims=True) * lr\n","    W1 += X.T.dot(d_hidden) * lr\n","    b1 += np.sum(d_hidden, axis=0, keepdims=True) * lr\n","\n","    if epoch % 1000 == 0:\t\t\t\t   \t                                            # Print error every 1000 iterations\n","        print(f\"Epoch {epoch}, Error: {np.mean(np.abs(error))}\")\n","\n","print(\"\\nTrained output:\")\t\t\t\t\t\t                                          # Output the result after training\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tFV90pl1KWG9","executionInfo":{"status":"ok","timestamp":1749409039702,"user_tz":-330,"elapsed":1260,"user":{"displayName":"SRUSHTI DHOTRE","userId":"06050880057213308556"}},"outputId":"57faf1cd-b29b-4ff4-c82e-6b8d41fe4e59"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Error: 0.4977550305860017\n","Epoch 1000, Error: 0.48962844155619734\n","Epoch 2000, Error: 0.430505591830237\n","Epoch 3000, Error: 0.335726373976126\n","Epoch 4000, Error: 0.17357496319517723\n","Epoch 5000, Error: 0.11181272498560173\n","Epoch 6000, Error: 0.08576413241547484\n","Epoch 7000, Error: 0.07130866479694536\n","Epoch 8000, Error: 0.061975191385776986\n","Epoch 9000, Error: 0.05537218409879135\n","\n","Trained output:\n","[[0.05322146]\n"," [0.95171535]\n"," [0.95160449]\n"," [0.05175396]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cceF_omcK49f"},"execution_count":null,"outputs":[]}]}