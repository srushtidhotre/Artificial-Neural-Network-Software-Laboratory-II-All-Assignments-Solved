{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM5BZp04AbZgnM3kPE/0vn1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["A6. Write a python program to recognize the number 0, 1, 2, 39. A 5 * 3 matrix forms the numbers. For\n","any valid point it is taken as 1 and invalid point it is taken as 0. The net has to be trained to recognize\n","all the numbers and when the test data is given, the network has to recognize the particular numbers."],"metadata":{"id":"fmVn-3f117Vs"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UYYuKgVcnuWe","executionInfo":{"status":"ok","timestamp":1749405260304,"user_tz":-330,"elapsed":594,"user":{"displayName":"SRUSHTI DHOTRE","userId":"06050880057213308556"}},"outputId":"0e210570-8628-43c9-eb17-95146ae26fd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 - Loss: 0.3578804529126451\n","Predicted class: 13\n","Epoch 1000 - Loss: 0.0026652307206991403\n","Predicted class: 0\n","Epoch 2000 - Loss: 0.0008410337324715074\n","Predicted class: 0\n","Epoch 3000 - Loss: 0.0004241231026176905\n","Predicted class: 0\n","Epoch 4000 - Loss: 0.0002762772237305808\n","Predicted class: 0\n","Epoch 5000 - Loss: 0.00020639571457729293\n","Predicted class: 0\n","Epoch 6000 - Loss: 0.00016485775463655488\n","Predicted class: 0\n","Epoch 7000 - Loss: 0.00013722735366076313\n","Predicted class: 0\n","Epoch 8000 - Loss: 0.00011750547364064601\n","Predicted class: 0\n","Epoch 9000 - Loss: 0.00010271952772799787\n","Predicted class: 0\n"]}],"source":["import numpy as np\n","\n","# 5x3 binary matrix representation of the numbers 0, 1, 3, and 39\n","X = np.array([\n","    [1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0],                              # 0\n","    [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],                              # 1\n","    [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1],                              # 3\n","    [1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0],                              # 39\n","])\n","\n","y = np.array([0, 1, 3, 39])                                                     # Labels for 0, 1, 3, 39\n","\n","y_one_hot = np.zeros((y.size, 40))                                              # Convert labels to one-hot encoding (for 40 classes)\n","y_one_hot[np.arange(y.size), y] = 1\n","\n","# Initialize weights and biases for the network\n","input_size = 15                                                                 # 5x3 flattened input\n","hidden_size = 8\n","output_size = 40                                                                # 40 output classes (digits 0â€“39)\n","\n","np.random.seed(42)                                                              # For reproducibility\n","\n","W1 = np.random.randn(input_size, hidden_size)                                   # Weights from input to hidden layer\n","b1 = np.zeros(hidden_size)                                                      # Bias for hidden layer\n","W2 = np.random.randn(hidden_size, output_size)                                  # Weights from hidden to output layer\n","b2 = np.zeros(output_size)                                                      # Bias for output layer\n","\n","def sigmoid(x):                                                                 # Sigmoid activation function\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):                                                      # Sigmoid derivative for backpropagation\n","    return x * (1 - x)\n","\n","learning_rate = 0.1                                                             # Learning rate for gradient descent\n","epochs = 10000\n","\n","for epoch in range(epochs):\n","\n","    hidden_layer_input = np.dot(X, W1) + b1                                     # Forward pass\n","    hidden_layer_output = sigmoid(hidden_layer_input)\n","    output_layer_input = np.dot(hidden_layer_output, W2) + b2\n","    output_layer_output = sigmoid(output_layer_input)\n","\n","    output_error = y_one_hot - output_layer_output                              # Compute error and output delta\n","    output_delta = output_error * sigmoid_derivative(output_layer_output)\n","\n","    hidden_error = output_delta.dot(W2.T)                                       # Backpropagation\n","    hidden_delta = hidden_error * sigmoid_derivative(hidden_layer_output)\n","\n","    W2 += hidden_layer_output.T.dot(output_delta) * learning_rate               # Update weights and biases\n","    b2 += np.sum(output_delta, axis=0) * learning_rate\n","    W1 += X.T.dot(hidden_delta) * learning_rate\n","    b1 += np.sum(hidden_delta, axis=0) * learning_rate\n","\n","    if epoch % 1000 == 0:\n","        loss = np.mean(np.square(output_error))\n","        print(f'Epoch {epoch} - Loss: {loss}')                                  # Print loss every 1000 epochs\n","\n","        test_input = np.array([[1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0]])  # Test the network with an example input ('0')\n","        hidden_layer_input = np.dot(test_input, W1) + b1\n","        hidden_layer_output = sigmoid(hidden_layer_input)\n","        output_layer_input = np.dot(hidden_layer_output, W2) + b2\n","        output_layer_output = sigmoid(output_layer_input)\n","\n","        predicted_class = np.argmax(output_layer_output)                        # Get predicted class\n","        print(f\"Predicted class: {predicted_class}\")                            # Should predict 0"]},{"cell_type":"code","source":[],"metadata":{"id":"w21uSpfoql1V"},"execution_count":null,"outputs":[]}]}